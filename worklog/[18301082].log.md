

## **7.8**

**AM**

1.和服务器组对接

将文件的暂时版本给他们，并解释其使用方法

2.优化原函数*1

**PM**

1.优化原函数*2

现在每次输入地区和日期后会自动计算接下来一周的最高温最低温并保存。优化的地方在于每次预测时都会把原来的中间文件给覆盖掉，避免空间过大

2.从nocc网站上下载所有省会的数据

## **7.7**

**AM**

1.重新确定分工

我们组最终确定分工为我负责建模和提供接口，张正阳和武熠彬负责后端服务器，使用java spring boot开发，赵康辉，林小倩使用vue进行前端页面开发。最终只需要把vue打包就可以放在spring boot用，做到前后端分离。现在的问题是感觉我们进程过慢，感觉很难完成之后的支线任务。

2.将模型方面功能函数化

方便调用

**PM**

1.考虑pq的确定

由于肉眼看很慢，也做不到自动化。所以我采用将pq从1到6跑一遍模型，通过bic的值，确定最终的pq值。

2.确定每一天的pq值并写入文件

避免前端网页调用时，演算时间过长，所以我先把每一天的模型都跑一遍，将最终确定的pq写入文件，这样预测时只需要从文件读相应pq就行了，节省时间。但问题是pq基本集中在1，2，鲜有3，4。（可能是数据集本身的问题，因为我问别人基本是同样的答案）

3.完成简单的接口函数

实现输入地区和时间，最终输出之后7天的预测结果。

## **7.6**

**AM**

1.第一次答辩

听了好多组的进程，感觉明显我们组有一些滞后。同时碰到问题，我无法理解两个框架Flask和java spring的作用，导致我不清楚怎么分配任务，项目停滞。同时也有别的组碰到相同问题，老师讲完我也不是很理解。

**PM**

1.询问两个框架的作用

询问多个组，但仍没有进展。他们有的组打算只使用Flask，而有的组只用了java spring boot，无需考虑两个框架之间的连接与交互。然后询问了老师，得到答复如下：

【flask是算法的后端，springboot是网页的后端，最后连接是flask和springboot都创建一个websocket进行数据交互。websocket可以实现Java和python的跨语言交互。】

所以相当于创建了两个服务器，flask是算法的后端，负责获得前端的参数后进行运算并返回预测结果。spring boot是网页的后端，负责响应网页的登录、注册等功能。

2.了解前后端分离

查询并了解了前后端分离的真正含义，感觉之前分工时，我完全没有理解此概念。见图。但说实话我总是担心两者的集成，感觉在没有学习前很迷茫。

![preview](https://pic3.zhimg.com/v2-889ced410c2319dbed2fe21c2da6e344_r.jpg)

## **7.5**

**AM**

1.Flask配置

比较简单，没有问题

2.Flask学习

有点没头绪，等下午继续学习

**PM**

1.PPT制作

明天答辩，简单地做了一下PPT，展示已完成内容

2.Flask学习

## **7.4**

**AM**

1.全年数据清洗

更改了数据清洗代码，完成了1981年到2012年（因为12年之后数据缺失项多）的每一天的数据清洗，并写入相应的csv文件

2.创建Python处理类，生成json格式数据

较为顺利



**PM**

1.json数据标准化

修改预测数据的日期由12-31为对应日期，并生成预测图和标准json文件

2.开会分享进度

进度比较缓慢，尤其是前端方面比较迷茫，花了大量时间学习但进展很慢。主要原因还是对于前端web网页和服务器之间的连接部分的知识缺失，也无从下手。暂且打算多问问其他组的想法加上自我的学习。

## **7.3**

**AM**

1.数据清洗

其实昨天就做了，今天对其的理解更深刻。简单地对csv文件进行了清洗，获得了只有DATE、TMAX、TMIN的csv文件。学会了对数据的筛选和过滤空项。

2.ARIMA模型研究

对ARIMA模型的继续研究，较为明白地理解了其原理和检验相关内容。

**PM**

1.初步建立基于时间序列的模型

基本掌握了模型的使用方法，部分原理，检验标准等。但是遇到了一个问题，即模型的p  q只能人工肉眼确定，误差大。故转而寻找网上相应代码，并成功使用BIC来进行检验确定最佳的p q值。但同时涌现新的问题，基本p q都是在取0 1 2时，BIC最小，自我认为有一定的问题，留待明日研究。

## **7.2**

**AM**

1.老师进行小组抽查进度

​		我借此了解别的组的进度和对项目的理解和分工。

2.配置虚拟机

​		配置时发现开启三台虚拟机时电脑无法正常运行，故让小组成员在被提问时，询问spark集群的意义。得到结论：【电脑开启三台虚拟机，使用spark集群是为了提高处理数据的能力和效率，（类似饭店一次请了3个厨师QAQ）。然而由于笔记本电脑配置的原因，无法正常运行，故反而影响效率】所以最终我们组决定暂时使用windows下单节点处理数据。而这个数据也只是任务实现上要求的北京的气温数据，暂时不动老师给的100G数据，留待我们完成1次迭代后，拓展时研究。

**PM**

1.老师讲解任务之间的关系

​		终于了解到任务建的关系。尤其是flask、json和Tomcat等之间的联系。目前我们组的理解是，flask是用于python传出预测的数据，json是传输数据的格式，tomact用作调用python的微程序接口获得预测的数据。

2.小组任务再明确

​	由于对之后几个任务的不明确，我们的前端开发小组成员不清楚从哪里属于前端的任务，故进度停滞。再明确后，确立他们先学习HTML5和CSS，再做出一个初步的web网页。前后端对接将由我们完成各自任务后再共同解决。

3.ARIMA模型初步学习

​	还不甚理解，晚上继续

## **7.1**

**感想**

​	甚是惭愧，身为小组长今天才在配置虚拟机的时候第一次发现，我因为对整个项目的不了解一	直对项目的分工很粗略，两天来一直放任组员自由配置，然后出现问题帮助解决，时间花费巨	大而项目进程推进缓慢，小组成员也较为迷惘。所以今日我仔细研究了项目进程，询问了多个	同学（实名感谢张璞、童路勤、何文龙），另外也观摩了隔壁班别的小组的会议，对项目有了	较为宏观的总体认识。最终在这个下午我对项目任务进行了分解和再分配。暂时本周任务具体	分为

​	【spark数据清洗】王昱、张正阳

​	【前端设计】赵康辉、林小倩

​	【模型设计】武熠彬（王昱、张正阳在掌握spark数据清洗的技术后加入研究模型设计，因为我觉得这点是最难理解，也是最需要突破的地方）

​	望老师多加指正！（我第一次当小组长，小组成员和我也不够“大腿”没有足够的经验）

**AM**

1.重新下载安装新版ubuntu。

​	配置网络时由于找不到pdf所示的edit connections选项，故停滞许久。然后从同学处了解到新版	无需配置Ipv4,。之后在打开ssh服务处停滞，始终显示无etc\init.d命令。然之后发现无需手动打	开，他在下载后自动打开了。

2.下载Xshell并成功与虚拟机连接

​	无大障碍

**PM**

1.建立主节点master从节点slave1和slave2，并成功实现互ping

​	但是我的笔记本似乎不支持3个虚拟机同时打开，会卡住，我甚至直接黑屏重启了。

2.突然醒悟，开始从项目整体来看，并多方咨询，最终有所了解

​	具体见上文【感想】

3.组织小组讨论，进行任务重分配和疑惑解答

## **6.30.**

AM

1.创建worklog文件夹并上传至远程仓库

2.配置成功Python和Pycharm（jdk1.8本来就有）

3.配置Spark和hadoop，失败2次，似乎是版本问题，仍在尝试

PM

1.成功配置Spark和hadoop（重下并配置jdk1.8）

2.成功安装VMware Workstation

3.成功下载ubuntu文件并成功在VMware里安装，但还未配置



